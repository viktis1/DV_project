{'sample_max_value', 'prediction_type', 'timestep_spacing', 'variance_type', 'dynamic_thresholding_ratio', 'thresholding', 'rescale_betas_zero_snr', 'clip_sample_range'} was not found in config. Values will be initialized to default values.
{'latents_std', 'mid_block_add_attention', 'latents_mean', 'scaling_factor', 'force_upcast', 'use_quant_conv', 'shift_factor', 'use_post_quant_conv'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing AutoencoderKL.

All the weights of AutoencoderKL were initialized from the model checkpoint at stable-diffusion-v1-5/stable-diffusion-v1-5.
If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderKL for predictions without further training.
{'time_embedding_act_fn', 'use_linear_projection', 'dual_cross_attention', 'dropout', 'mid_block_only_cross_attention', 'upcast_attention', 'projection_class_embeddings_input_dim', 'resnet_out_scale_factor', 'class_embeddings_concat', 'num_attention_heads', 'mid_block_type', 'time_embedding_type', 'attention_type', 'conv_in_kernel', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'timestep_post_act', 'addition_time_embed_dim', 'addition_embed_type', 'num_class_embeds', 'encoder_hid_dim_type', 'time_cond_proj_dim', 'class_embed_type', 'resnet_time_scale_shift', 'resnet_skip_time_act', 'only_cross_attention', 'time_embedding_dim', 'addition_embed_type_num_heads', 'conv_out_kernel', 'cross_attention_norm', 'transformer_layers_per_block'} was not found in config. Values will be initialized to default values.
All model checkpoint weights were used when initializing UNet2DConditionModel.

All the weights of UNet2DConditionModel were initialized from the model checkpoint at stable-diffusion-v1-5/stable-diffusion-v1-5.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UNet2DConditionModel for predictions without further training.
Total trainable LoRA parameters: 51019776
***** Running training *****
  Num examples = 223414
  Num Epochs = 1
  Instantaneous batch size per device = 2
  Total train batch size (w. parallel, distributed & accumulation) = 4
  Gradient Accumulation steps = 2
  Total optimization steps = 5000
Checkpoint 'latest' does not exist. Starting a new training run.
Steps:   0%|‚ñè                                                                                                                                 | 5/5000 [00:07<1:26:06,  1.03s/it, loss=0.351, lr=0.0001]Traceback (most recent call last):
  File "C:\Users\isaks\OneDrive - Danmarks Tekniske Universitet\DTU\10semester\Adv_DL_CV\project\SD_finetuning_train.py", line 477, in <module>
    main()
  File "C:\Users\isaks\OneDrive - Danmarks Tekniske Universitet\DTU\10semester\Adv_DL_CV\project\SD_finetuning_train.py", line 377, in main
    model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\accelerate\utils\operations.py", line 814, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\accelerate\utils\operations.py", line 802, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\amp\autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\diffusers\models\unets\unet_2d_condition.py", line 1279, in forward
    sample = upsample_block(
             ^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\diffusers\models\unets\unet_2d_blocks.py", line 2458, in forward
    hidden_states = attn(
                    ^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\diffusers\models\transformers\transformer_2d.py", line 427, in forward
    hidden_states = block(
                    ^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\diffusers\models\attention.py", line 514, in forward
    attn_output = self.attn1(
                  ^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\diffusers\models\attention_processor.py", line 605, in forward
    return self.processor(
           ^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\diffusers\models\attention_processor.py", line 3295, in __call__
    key = attn.to_k(encoder_hidden_states)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\peft\tuners\lora\layer.py", line 727, in forward
    result = result + lora_B(lora_A(dropout(x))) * scaling
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\isaks\miniconda3\envs\adv_dl_cv\Lib\site-packages\torch\nn\modules\module.py", line 1741, in _call_impl
    forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
